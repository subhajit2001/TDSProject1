{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKnf6iBec6Sr"
   },
   "outputs": [],
   "source": [
    "#users.csv\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# Replace with your personal access token\n",
    "GITHUB_TOKEN = '#'\n",
    "HEADERS = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
    "BASE_URL = 'https://api.github.com'\n",
    "\n",
    "def get_users_in_bangalore():\n",
    "    users = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(f'{BASE_URL}/search/users',\n",
    "                                headers=HEADERS,\n",
    "                                params={'q': 'location:Mumbai followers:>50', 'page': page})\n",
    "        data = response.json()\n",
    "\n",
    "        if 'items' not in data or not data['items']:\n",
    "            break\n",
    "\n",
    "        for user in data['items']:\n",
    "            users.append(user['login'])\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    return users\n",
    "\n",
    "def get_user_details(username):\n",
    "    response = requests.get(f'{BASE_URL}/users/{username}', headers=HEADERS)\n",
    "    return response.json()\n",
    "\n",
    "def clean_company(company):\n",
    "    if company:\n",
    "        return company.strip().lstrip('@').upper()\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    users = get_users_in_bangalore()\n",
    "    user_details = []\n",
    "\n",
    "    for user in users:\n",
    "        details = get_user_details(user)\n",
    "        user_details.append({\n",
    "            'login': details.get('login'),\n",
    "            'name': details.get('name'),\n",
    "            'company': clean_company(details.get('company')),\n",
    "            'location': details.get('location'),\n",
    "            'email': details.get('email'),\n",
    "            'hireable': details.get('hireable'),\n",
    "            'bio': details.get('bio'),\n",
    "            'public_repos': details.get('public_repos'),\n",
    "            'followers': details.get('followers'),\n",
    "            'following': details.get('following'),\n",
    "            'created_at': details.get('created_at'),\n",
    "        })\n",
    "\n",
    "    # Write to CSV\n",
    "    with open('users.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['login', 'name', 'company', 'location', 'email',\n",
    "                      'hireable', 'bio', 'public_repos', 'followers',\n",
    "                      'following', 'created_at']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for user in user_details:\n",
    "            writer.writerow(user)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cuaQL_mZrBU1",
    "outputId": "da458140-f4fe-429f-d5a9-67447b62e4bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company names cleaned and saved to users.csv.\n"
     ]
    }
   ],
   "source": [
    "#more cleaned users.csv\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Clean the company names\n",
    "users_df['company'] = users_df['company'].str.strip()  # Trim whitespace\n",
    "users_df['company'] = users_df['company'].str.lstrip('@')  # Strip leading '@'\n",
    "users_df['company'] = users_df['company'].str.upper()  # Convert to uppercase\n",
    "\n",
    "# Save the cleaned DataFrame back to users.csv\n",
    "users_df.to_csv('users.csv', index=False)\n",
    "\n",
    "print(\"Company names cleaned and saved to users.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqENI4TufvGy"
   },
   "outputs": [],
   "source": [
    "#repositories.csv\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# Replace with your personal access token\n",
    "GITHUB_TOKEN = '#'\n",
    "HEADERS = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
    "BASE_URL = 'https://api.github.com'\n",
    "\n",
    "def read_users_from_csv(file_path):\n",
    "    users = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            users.append(row['login'])\n",
    "    return users\n",
    "\n",
    "def get_repositories(username):\n",
    "    repos = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        response = requests.get(f'{BASE_URL}/users/{username}/repos',\n",
    "                                headers=HEADERS,\n",
    "                                params={'sort': 'pushed', 'direction': 'desc', 'per_page': 100, 'page': page})\n",
    "        data = response.json()\n",
    "\n",
    "        if not data or len(repos) >= 500:\n",
    "            break\n",
    "\n",
    "        for repo in data:\n",
    "            repos.append({\n",
    "                'full_name': repo['full_name'],\n",
    "                'created_at': repo['created_at'],\n",
    "                'stargazers_count': repo['stargazers_count'],\n",
    "                'watchers_count': repo['watchers_count'],\n",
    "                'language': repo['language'],\n",
    "                'has_projects': repo['has_projects'],\n",
    "                'has_wiki': repo['has_wiki'],\n",
    "                'license_name': repo['license']['key'] if repo.get('license') else None  # Safely fetch license key\n",
    "            })\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    return repos[:500]  # Return up to 500 repos\n",
    "\n",
    "def main():\n",
    "    users = read_users_from_csv('users.csv')\n",
    "    all_repos = []\n",
    "\n",
    "    for user in users:\n",
    "        repos = get_repositories(user)\n",
    "        for repo in repos:\n",
    "            all_repos.append({\n",
    "                'login': user,\n",
    "                **repo\n",
    "            })\n",
    "\n",
    "    # Write to CSV\n",
    "    with open('repositories.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['login', 'full_name', 'created_at',\n",
    "                      'stargazers_count', 'watchers_count',\n",
    "                      'language', 'has_projects',\n",
    "                      'has_wiki', 'license_name']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for repo in all_repos:\n",
    "            writer.writerow(repo)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7CkS3Zam87L",
    "outputId": "129e0987-13e1-4ca3-cd80-64c290e3683d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValentineFernandes, kovidgoyal, slidenerd, aryashah2k, coding-parrot\n"
     ]
    }
   ],
   "source": [
    "#Q1\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Sort by followers and get top 5\n",
    "top_users = users_df.sort_values(by='followers', ascending=False).head(5)\n",
    "\n",
    "# Extract logins\n",
    "top_logins = top_users['login'].tolist()\n",
    "result = ', '.join(top_logins)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jVT8tVpipe8W",
    "outputId": "626f4368-cf8c-464f-ce8c-a2ecf07a35cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ivank, sandeepshetty, svs, nitinhayaran, nischal\n"
     ]
    }
   ],
   "source": [
    "#Q2\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Convert created_at to datetime\n",
    "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
    "\n",
    "# Sort by created_at and get the earliest 5 users\n",
    "earliest_users = users_df.sort_values(by='created_at').head(5)\n",
    "\n",
    "# Extract logins\n",
    "earliest_logins = earliest_users['login'].tolist()\n",
    "result = ', '.join(earliest_logins)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0v3-8fq7p5qY",
    "outputId": "566ade50-0e3b-4cc4-e570-31d281a99e09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mit, apache-2.0, other\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "repositories_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Filter out missing license names\n",
    "repositories_df = repositories_df[repositories_df['license_name'].notna()]\n",
    "\n",
    "# Count occurrences of each license\n",
    "license_counts = repositories_df['license_name'].value_counts()\n",
    "\n",
    "# Get the top 3 licenses\n",
    "top_licenses = license_counts.head(3).index.tolist()\n",
    "\n",
    "# Join the license names in order\n",
    "result = ', '.join(top_licenses)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zPFLL9pdrI7h",
    "outputId": "7642a0a3-b67f-4e06-b467-9973c3e0e2be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The majority of developers work at: MASAI SCHOOL with 14 developers.\n"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Count occurrences of each company\n",
    "company_counts = users_df['company'].value_counts()\n",
    "\n",
    "# Get the company with the highest count\n",
    "most_common_company = company_counts.idxmax()\n",
    "most_common_count = company_counts.max()\n",
    "\n",
    "print(f\"The majority of developers work at: {most_common_company} with {most_common_count} developers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tUbmeG3KrTqI",
    "outputId": "86c9fe8b-1451-4f41-818b-8ce5f4d9b6a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most popular programming language is: JavaScript with 8163 repositories.\n"
     ]
    }
   ],
   "source": [
    "#Q5\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "repositories_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Count occurrences of each programming language, ignoring missing values\n",
    "language_counts = repositories_df['language'].value_counts()\n",
    "\n",
    "# Get the most popular programming language\n",
    "most_popular_language = language_counts.idxmax()\n",
    "most_popular_count = language_counts.max()\n",
    "\n",
    "print(f\"The most popular programming language is: {most_popular_language} with {most_popular_count} repositories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JUqfwgare6t",
    "outputId": "8c559432-7e25-4bf0-ede5-4a5a3928ea83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second most popular programming language among users who joined after 2020 is: HTML with 1295 repositories.\n"
     ]
    }
   ],
   "source": [
    "#Q6\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "users_df = pd.read_csv('users.csv')\n",
    "repositories_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Convert created_at to datetime and filter users who joined after 2020\n",
    "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
    "recent_users = users_df[users_df['created_at'] > '2020-01-01']\n",
    "\n",
    "# Get the logins of recent users\n",
    "recent_user_logins = recent_users['login'].tolist()\n",
    "\n",
    "# Filter repositories by these users\n",
    "recent_repositories = repositories_df[repositories_df['login'].isin(recent_user_logins)]\n",
    "\n",
    "# Count occurrences of each programming language\n",
    "language_counts = recent_repositories['language'].value_counts()\n",
    "\n",
    "# Get the second most popular programming language\n",
    "second_most_popular_language = language_counts.nlargest(2).index[1]\n",
    "second_most_popular_count = language_counts.nlargest(2).values[1]\n",
    "\n",
    "print(f\"The second most popular programming language among users who joined after 2020 is: {second_most_popular_language} with {second_most_popular_count} repositories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aowu8SiZrp_P",
    "outputId": "96f13809-5ba9-4cd4-df6f-766b81761421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The programming language with the highest average number of stars per repository is: TSQL with an average of 571.15 stars.\n"
     ]
    }
   ],
   "source": [
    "#Q7\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "repositories_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Group by programming language and calculate the average stars\n",
    "average_stars = repositories_df.groupby('language')['stargazers_count'].mean()\n",
    "\n",
    "# Identify the language with the highest average stars\n",
    "highest_average_language = average_stars.idxmax()\n",
    "highest_average_value = average_stars.max()\n",
    "\n",
    "print(f\"The programming language with the highest average number of stars per repository is: {highest_average_language} with an average of {highest_average_value:.2f} stars.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oy6f8ZBcr4xS",
    "outputId": "07e4650b-2f6a-46ac-c3a3-a2fe8d3e830a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kovidgoyal, coding-parrot, gkcs, slidenerd, dmalvia\n"
     ]
    }
   ],
   "source": [
    "#Q8\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Calculate leader_strength\n",
    "users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n",
    "\n",
    "# Sort by leader_strength and get the top 5\n",
    "top_leaders = users_df.sort_values(by='leader_strength', ascending=False).head(5)\n",
    "\n",
    "# Extract logins\n",
    "top_logins = top_leaders['login'].tolist()\n",
    "result = ', '.join(top_logins)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b17bFXSwsSsP",
    "outputId": "07c71fae-3422-4b44-cf6a-37723ed0cc97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between the number of followers and the number of public repositories is: 0.035\n"
     ]
    }
   ],
   "source": [
    "#Q9\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Calculate the correlation between followers and public repositories\n",
    "correlation = users_df['followers'].corr(users_df['public_repos'])\n",
    "\n",
    "print(f\"The correlation between the number of followers and the number of public repositories is: {correlation:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.1-cp38-cp38-win_amd64.whl (10.0 MB)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in c:\\users\\subha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from statsmodels) (1.10.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\subha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: numpy<2,>=1.18 in c:\\users\\subha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from statsmodels) (1.24.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.0 in c:\\users\\subha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from statsmodels) (2.0.3)\n",
      "Collecting patsy>=0.5.4\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\subha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\subha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\subha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: six in c:\\users\\subha\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.6 statsmodels-0.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\subha\\AppData\\Local\\Programs\\Python\\Python38\\python38.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python38 -m pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kT3YZzPsoBw",
    "outputId": "86b62195-b5ce-4221-d36f-771648a4f7eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Results:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              followers   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.8636\n",
      "Date:                Thu, 31 Oct 2024   Prob (F-statistic):              0.353\n",
      "Time:                        00:24:02   Log-Likelihood:                -5245.0\n",
      "No. Observations:                 725   AIC:                         1.049e+04\n",
      "Df Residuals:                     723   BIC:                         1.050e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const          150.4084     14.129     10.646      0.000     122.671     178.146\n",
      "public_repos     0.1010      0.109      0.929      0.353      -0.112       0.314\n",
      "==============================================================================\n",
      "Omnibus:                     1181.491   Durbin-Watson:                   0.042\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           451398.527\n",
      "Skew:                           9.960   Prob(JB):                         0.00\n",
      "Kurtosis:                     123.607   Cond. No.                         147.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Estimated additional followers per additional public repository: 0.101\n"
     ]
    }
   ],
   "source": [
    "#Q10\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the data\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Define the independent variable (X) and dependent variable (Y)\n",
    "X = users_df['public_repos']\n",
    "Y = users_df['followers']\n",
    "\n",
    "# Add a constant to the independent variable (for the intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Get the summary of the regression results\n",
    "summary = model.summary()\n",
    "\n",
    "# Extract the coefficient for public_repos\n",
    "additional_followers_per_repo = model.params['public_repos']\n",
    "\n",
    "print(f\"Regression Results:\\n{summary}\")\n",
    "print(f\"Estimated additional followers per additional public repository: {additional_followers_per_repo:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_QxL3kys-_z",
    "outputId": "7db2d2fa-e64f-47b4-cb97-fbdbafd6c4dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between having projects enabled and having a wiki enabled is: 0.160\n"
     ]
    }
   ],
   "source": [
    "#Q11\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "repositories_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "\n",
    "# Calculate the correlation directly\n",
    "correlation = repositories_df['has_projects'].astype(int).corr(repositories_df['has_wiki'].astype(int))\n",
    "\n",
    "print(f\"The correlation between having projects enabled and having a wiki enabled is: {correlation:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0D_j97ouhM_",
    "outputId": "bac257b1-8ff5-4339-bf4a-3f15ba613b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in average following (hireable - non-hireable): 8.708\n"
     ]
    }
   ],
   "source": [
    "#Q12\n",
    "import pandas as pd\n",
    "\n",
    "# Load the users data from the CSV file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Filter hireable and non-hireable users\n",
    "hireable_users = users_df[users_df['hireable'] == True]\n",
    "non_hireable_users = users_df[users_df['hireable'].isna() | (users_df['hireable'] == False)]\n",
    "\n",
    "# Calculate average following for both groups\n",
    "average_hireable_following = hireable_users['following'].mean()\n",
    "average_non_hireable_following = non_hireable_users['following'].mean()\n",
    "\n",
    "# Calculate the difference\n",
    "difference = average_hireable_following - average_non_hireable_following\n",
    "\n",
    "# Print the result rounded to three decimal places\n",
    "print(f'Difference in average following (hireable - non-hireable): {difference:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t86gGTj6uhLn",
    "outputId": "fc4feb15-bb71-4256-abaa-e61f46afbb10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression slope of followers on bio word count: -0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subha\\AppData\\Local\\Temp\\ipykernel_12412\\1755056196.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users_with_bios['bio_word_count'] = users_with_bios['bio'].apply(lambda x: len(x.split()))\n"
     ]
    }
   ],
   "source": [
    "#Q13\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the users data from the CSV file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Filter out users without bios\n",
    "users_with_bios = users_df[users_df['bio'].notna()]\n",
    "\n",
    "# Calculate the length of the bio in words\n",
    "#users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split(\" \").str.len()\n",
    "\n",
    "users_with_bios['bio_word_count'] = users_with_bios['bio'].apply(lambda x: len(x.split()))\n",
    "\n",
    "\n",
    "# Prepare the data for regression\n",
    "X = users_with_bios['bio_word_count']  # Independent variable\n",
    "y = users_with_bios['followers']        # Dependent variable\n",
    "\n",
    "# Add a constant to the independent variable for the regression\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Get the regression slope (coefficient for bio_word_count)\n",
    "slope = model.params['bio_word_count']\n",
    "\n",
    "# Print the slope rounded to three decimal places\n",
    "print(f'Regression slope of followers on bio word count: {slope:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69dBDEpH3DXl",
    "outputId": "c1dc016b-b3e7-4b67-c40f-e16ecda45a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 users who created the most repositories on weekends: Kushal334, alokproc, vinod1988, patilswapnilv, rajeshpillai\n"
     ]
    }
   ],
   "source": [
    "#Q14\n",
    "import pandas as pd\n",
    "\n",
    "# Load the repositories data from the CSV file\n",
    "repos_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Convert the created_at column to datetime\n",
    "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
    "\n",
    "# Filter for weekend days (Saturday: 5, Sunday: 6)\n",
    "weekend_repos = repos_df[repos_df['created_at'].dt.dayofweek.isin([5, 6])]\n",
    "\n",
    "# Count the number of repositories created by each user\n",
    "top_users = weekend_repos['login'].value_counts().head(5)\n",
    "\n",
    "# Get the top 5 users' logins in order\n",
    "top_users_logins = ', '.join(top_users.index)\n",
    "\n",
    "# Print the result\n",
    "print(f'Top 5 users who created the most repositories on weekends: {top_users_logins}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozqOj5bd3DWQ",
    "outputId": "2418eea9-85ef-42a3-d521-51e58e563aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in fraction of users with email: 0.221\n"
     ]
    }
   ],
   "source": [
    "#Q15\n",
    "import pandas as pd\n",
    "\n",
    "# Load the users data from the CSV file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Total number of users\n",
    "total_users = len(users_df)\n",
    "\n",
    "# Filter hireable and non-hireable users\n",
    "hireable_users = users_df[users_df['hireable'] == True]\n",
    "non_hireable_users = users_df[users_df['hireable'].isna() | (users_df['hireable'] == False)]\n",
    "\n",
    "# Calculate the fraction of users with email in both groups\n",
    "fraction_hireable_with_email = hireable_users['email'].notna().mean()\n",
    "fraction_non_hireable_with_email = non_hireable_users['email'].notna().mean()\n",
    "\n",
    "# Calculate the difference\n",
    "difference = fraction_hireable_with_email - fraction_non_hireable_with_email\n",
    "\n",
    "# Print the result rounded to three decimal places\n",
    "print(f'Difference in fraction of users with email: {difference:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6MCRKTWM3eGI",
    "outputId": "7caf6b1e-424a-423b-8793-fdc5aa551ce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common surname(s): Singh\n",
      "Number of users with the most common surname: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subha\\AppData\\Local\\Temp\\ipykernel_12412\\2579288886.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_users['surname'] = valid_users['name'].str.strip().str.split().str[-1]\n"
     ]
    }
   ],
   "source": [
    "#Q16\n",
    "import pandas as pd\n",
    "\n",
    "# Load the users data from the CSV file\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Filter out users without names\n",
    "valid_users = users_df[users_df['name'].notna()]\n",
    "\n",
    "# Extract surnames (last word in name)\n",
    "valid_users['surname'] = valid_users['name'].str.strip().str.split().str[-1]\n",
    "\n",
    "# Count occurrences of each surname\n",
    "surname_counts = valid_users['surname'].value_counts()\n",
    "\n",
    "# Find the most common surname(s)\n",
    "max_count = surname_counts.max()\n",
    "most_common_surnames = surname_counts[surname_counts == max_count].index.tolist()\n",
    "\n",
    "# Sort surnames alphabetically\n",
    "most_common_surnames.sort()\n",
    "\n",
    "# Count users with the most common surname\n",
    "number_of_users = max_count\n",
    "\n",
    "# Print results\n",
    "most_common_surnames_str = ', '.join(most_common_surnames)\n",
    "print(f'Most common surname(s): {most_common_surnames_str}')\n",
    "print(f'Number of users with the most common surname: {number_of_users}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYYOmo-ND2ep"
   },
   "source": [
    "Wrong Answers In Q11, 12, 15 > because In Original Files, Booleans are True/False . We have to upload Booleans as true/false in github repo. Run Scripts below and then upload resulting files to github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICA9p7MoNx23"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHb14gzTJIXy",
    "outputId": "91c6a15f-1dae-4b85-8ee5-3a41cd6e3c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         login                           full_name            created_at  \\\n",
      "0  krishnaik06  krishnaik06/Polars-GPU-Engine-Demo  2024-10-28T08:42:45Z   \n",
      "1  krishnaik06  krishnaik06/Transformers-Materials  2024-10-19T15:43:30Z   \n",
      "2  krishnaik06              krishnaik06/ETLWeather  2024-10-15T10:45:09Z   \n",
      "3  krishnaik06                krishnaik06/datasets  2024-10-08T05:16:12Z   \n",
      "4  krishnaik06             krishnaik06/testdagshub  2024-10-01T16:57:42Z   \n",
      "\n",
      "   stargazers_count  watchers_count          language  has_projects  has_wiki  \\\n",
      "0                 1               1  Jupyter Notebook          True      True   \n",
      "1                10              10               NaN          True      True   \n",
      "2                 9               9            Python          True      True   \n",
      "3                 3               3               NaN          True      True   \n",
      "4                 0               0               NaN          True      True   \n",
      "\n",
      "  license_name  \n",
      "0      gpl-3.0  \n",
      "1      gpl-3.0  \n",
      "2      gpl-3.0  \n",
      "3      gpl-3.0  \n",
      "4          NaN  \n",
      "         login                           full_name            created_at  \\\n",
      "0  krishnaik06  krishnaik06/Polars-GPU-Engine-Demo  2024-10-28T08:42:45Z   \n",
      "1  krishnaik06  krishnaik06/Transformers-Materials  2024-10-19T15:43:30Z   \n",
      "2  krishnaik06              krishnaik06/ETLWeather  2024-10-15T10:45:09Z   \n",
      "3  krishnaik06                krishnaik06/datasets  2024-10-08T05:16:12Z   \n",
      "4  krishnaik06             krishnaik06/testdagshub  2024-10-01T16:57:42Z   \n",
      "\n",
      "   stargazers_count  watchers_count          language has_projects has_wiki  \\\n",
      "0                 1               1  Jupyter Notebook         true     true   \n",
      "1                10              10               NaN         true     true   \n",
      "2                 9               9            Python         true     true   \n",
      "3                 3               3               NaN         true     true   \n",
      "4                 0               0               NaN         true     true   \n",
      "\n",
      "  license_name  \n",
      "0      gpl-3.0  \n",
      "1      gpl-3.0  \n",
      "2      gpl-3.0  \n",
      "3      gpl-3.0  \n",
      "4          NaN  \n",
      "Updated CSV file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "repositories_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# Check the data types and structure\n",
    "print(repositories_df.head())\n",
    "\n",
    "# Replace True/False with true/false\n",
    "repositories_df['has_projects'] = repositories_df['has_projects'].replace({True: 'true', False: 'false'})\n",
    "repositories_df['has_wiki'] = repositories_df['has_wiki'].replace({True: 'true', False: 'false'})\n",
    "\n",
    "# Save the modified DataFrame back to the same CSV file\n",
    "repositories_df.to_csv('repositories.csv', index=False)\n",
    "\n",
    "# Check the data types and structure\n",
    "print(repositories_df.head())\n",
    "\n",
    "print(\"Updated CSV file saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TcHTWbzuJVDX",
    "outputId": "89c50de0-fbab-4f1d-edbe-8260fa3c88d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             login           name          company          location  \\\n",
      "0      krishnaik06   Krish C Naik    PANASONIC IIC         Bangalore   \n",
      "1  championswimmer    Arnav Gupta        JIOCINEMA  Bangalore, India   \n",
      "2    arpitbbhayani  Arpit Bhayani           DICEDB         Bangalore   \n",
      "3    manjunath5496    Manjunath.R  MYW3SCHOOLS.COM  Bangalore, India   \n",
      "4      tanaypratap   Tanay Pratap           INVACT  Bangalore, India   \n",
      "\n",
      "                     email hireable  \\\n",
      "0    krishnaik06@gmail.com      NaN   \n",
      "1   dev@championswimmer.in     True   \n",
      "2                      NaN     True   \n",
      "3  manjunath5496@gmail.com      NaN   \n",
      "4      tanay.mit@gmail.com      NaN   \n",
      "\n",
      "                                                 bio  public_repos  followers  \\\n",
      "0  Data Scientist with ML and Deep  Learning expe...           330      30906   \n",
      "1  Director of Engineering - @JioCinema ┃\\r\\nPast...           351       4661   \n",
      "2  Creator of @DiceDB • ex-Google Dataproc, ex-Am...           188       4557   \n",
      "3  \"Science is not only a disciple of reason but,...          1563       4084   \n",
      "4         Founder & CEO @invact . Teacher @neogcamp             40       3029   \n",
      "\n",
      "   following            created_at  \n",
      "0          0  2016-06-20T09:25:45Z  \n",
      "1         29  2012-01-13T07:41:40Z  \n",
      "2          3  2013-06-20T06:40:12Z  \n",
      "3       9313  2016-06-16T05:02:32Z  \n",
      "4          1  2014-12-17T05:15:06Z  \n",
      "             login           name          company          location  \\\n",
      "0      krishnaik06   Krish C Naik    PANASONIC IIC         Bangalore   \n",
      "1  championswimmer    Arnav Gupta        JIOCINEMA  Bangalore, India   \n",
      "2    arpitbbhayani  Arpit Bhayani           DICEDB         Bangalore   \n",
      "3    manjunath5496    Manjunath.R  MYW3SCHOOLS.COM  Bangalore, India   \n",
      "4      tanaypratap   Tanay Pratap           INVACT  Bangalore, India   \n",
      "\n",
      "                     email hireable  \\\n",
      "0    krishnaik06@gmail.com      NaN   \n",
      "1   dev@championswimmer.in     true   \n",
      "2                      NaN     true   \n",
      "3  manjunath5496@gmail.com      NaN   \n",
      "4      tanay.mit@gmail.com      NaN   \n",
      "\n",
      "                                                 bio  public_repos  followers  \\\n",
      "0  Data Scientist with ML and Deep  Learning expe...           330      30906   \n",
      "1  Director of Engineering - @JioCinema ┃\\r\\nPast...           351       4661   \n",
      "2  Creator of @DiceDB • ex-Google Dataproc, ex-Am...           188       4557   \n",
      "3  \"Science is not only a disciple of reason but,...          1563       4084   \n",
      "4         Founder & CEO @invact . Teacher @neogcamp             40       3029   \n",
      "\n",
      "   following            created_at  \n",
      "0          0  2016-06-20T09:25:45Z  \n",
      "1         29  2012-01-13T07:41:40Z  \n",
      "2          3  2013-06-20T06:40:12Z  \n",
      "3       9313  2016-06-16T05:02:32Z  \n",
      "4          1  2014-12-17T05:15:06Z  \n",
      "Updated CSV file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Check the data types and structure\n",
    "print(users_df.head())\n",
    "\n",
    "# Replace True/False with true/false in the hireable column\n",
    "users_df['hireable'] = users_df['hireable'].replace({True: 'true', False: 'false'})\n",
    "\n",
    "# Save the modified DataFrame back to the same CSV file\n",
    "users_df.to_csv('users.csv', index=False)\n",
    "\n",
    "# Check the data types and structure\n",
    "print(users_df.head())\n",
    "\n",
    "\n",
    "print(\"Updated CSV file saved successfully.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
